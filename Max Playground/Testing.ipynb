{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory that contains implementations.py\n",
    "sys.path.append(os.path.abspath(r\"../\"))\n",
    "\n",
    "from implementations import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "y = np.array([1, 2, 3, 4, 5])  # Output variable (target)\n",
    "tx = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])  # Input features\n",
    "initial_w = np.array([0.1, 0.1])  # Initial weights\n",
    "max_iters = 10000  # Maximum iterations\n",
    "gamma = 0.01  # Learning rate\n",
    "lambda_ = 0.001  # Regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent - Loss: 2.023042998290511e-08\n",
      "Gradient Descent - Weights: [9.99397409e-01 4.70488569e-04]\n",
      "Stochastic Gradient Descent - Loss: 2.014529963931782e-08\n",
      "Stochastic Gradient Descent - Weights: [9.99430930e-01 4.58081035e-04]\n",
      "Least Squares - Loss: 0.0\n",
      "Least Squares - Weights: [ 1. -0.]\n",
      "Ridge Regression - Loss: 2.8145778062758404e-06\n",
      "Ridge Regression - Weights: [0.99288225 0.00553578]\n",
      "loss=0.4427742051136673\n",
      "Logistic Regression - Loss: 0.6730121591904145\n",
      "Logistic Regression - Weights: [[ 0.40346027]\n",
      " [-0.40346027]]\n"
     ]
    }
   ],
   "source": [
    "# Test Gradient Descent with Mean Squared Error\n",
    "loss_gd, w_gd = mean_squared_error_gd(y, tx, initial_w, max_iters, gamma)\n",
    "print(\"Gradient Descent - Loss:\", loss_gd)\n",
    "print(\"Gradient Descent - Weights:\", w_gd)\n",
    "\n",
    "# Test Stochastic Gradient Descent\n",
    "loss_sgd, w_sgd = mean_squared_error_sgd(y, tx, initial_w, max_iters, gamma)\n",
    "print(\"Stochastic Gradient Descent - Loss:\", loss_sgd)\n",
    "print(\"Stochastic Gradient Descent - Weights:\", w_sgd)\n",
    "\n",
    "# Test Least Squares\n",
    "w_ls, loss_ls = least_squares(y, tx)\n",
    "print(\"Least Squares - Loss:\", loss_ls)\n",
    "print(\"Least Squares - Weights:\", w_ls)\n",
    "\n",
    "# Test Ridge Regression\n",
    "w_rr, loss_rr = ridge_regression(y, tx, lambda_)\n",
    "print(\"Ridge Regression - Loss:\", loss_rr)\n",
    "print(\"Ridge Regression - Weights:\", w_rr)\n",
    "\n",
    "# Test Logistic Regression\n",
    "y_binary = np.array([[0], [1], [0], [1], [0]])  # Example binary labels for logistic regression\n",
    "initial_w_log = np.zeros((tx.shape[1], 1))  # Initial weights for logistic regression\n",
    "w_log, loss_log = logistic_regression(y_binary, tx, initial_w_log, max_iters, gamma)\n",
    "print(\"Logistic Regression - Loss:\", loss_log)\n",
    "print(\"Logistic Regression - Weights:\", w_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.58257569495584"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1, 2, -4])\n",
    "np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
